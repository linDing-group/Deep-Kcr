{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build corpus\n",
    "def DNA2Sentence(dna, K):\n",
    "\n",
    "    sentence = \"\"\n",
    "    length = len(dna)\n",
    "\n",
    "    for i in range(length - K + 1):\n",
    "        sentence += dna[i: i + K] + \" \"\n",
    "\n",
    "    #delete extra space\n",
    "    sentence = sentence[0 : len(sentence) - 1]\n",
    "    return sentence\n",
    "\n",
    "def Get_Unsupervised(fname,gname,kmer):\n",
    "\tf = open(fname,'r')\n",
    "\tg = open(gname,'w')\n",
    "\tk = kmer\n",
    "\tfor i in f:\n",
    "\t\tif '>' not in i:\n",
    "\t\t\ti = i.strip('\\n').upper()\n",
    "\t\t\tline = DNA2Sentence(i,k)\n",
    "\t\t\tg.write(line+'\\n')\n",
    "\tf.close()\n",
    "\tg.close()\n",
    "\n",
    "Get_Unsupervised('pos.fasta','pos2Un',2)#postive samples contained in 'pos.fasta';'pos2Un' is outputFile of corpus;'2' is the size of Kmer\n",
    "Get_Unsupervised('neg.fasta','neg2Un',2)#negative samples contained in 'neg.fasta';'neg2Un' is outputFile of corpus;'2' is the size of Kmer\n",
    "\n",
    "#combine two corpus and generate final corpus\n",
    "with open('2Un','ab') as f:\n",
    "        f.write(open('pos2Un','rb').read())\n",
    "        f.write(open('neg2Un','rb').read())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Word2Vec model...\n",
      "Training Word2Vec model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1988a91b2c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get model\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "def getWord_model(word,num_features,min_count):\n",
    "\tword_model = \"\"\n",
    "\tif not os.path.isfile(\"model_2\"):\n",
    "\t\tsentence = LineSentence(\"2Un\",max_sentence_length = 15000)\n",
    "\t\tprint (\"Start Training Word2Vec model...\")\n",
    "\t\t# Set values for various parameters\n",
    "\t\tnum_features = int(num_features)\t  # Word vector dimensionality\n",
    "\t\tmin_word_count = int(min_count)\t  # Minimum word count\n",
    "\t\tnum_workers = 20\t\t # Number of threads to run in parallel并行运行的线程数\n",
    "\t\tcontext = 20\t\t\t# Context window size上下文窗口大小\n",
    "\t\tdownsampling = 1e-3\t # Downsample setting for frequent words常用词的下采样设置\n",
    "\n",
    "\t\t# Initialize and train the model初始化和训练模型\n",
    "\t\tprint (\"Training Word2Vec model...\")\n",
    "\t\tword_model = Word2Vec(sentence, workers=num_workers,\\\n",
    "\t\t\t\t\t\tsize=num_features, min_count=min_word_count, \\\n",
    "\t\t\t\t\t\twindow=context, sample=downsampling, seed=1,iter = 50)\n",
    "\t\tword_model.init_sims(replace=False)\n",
    "\t\tword_model.save(\"model_2\")\n",
    "\t\t#print word_model.most_similar(\"CATAGT\")\n",
    "\telse:\n",
    "\t\tprint (\"Loading Word2Vec model...\")\n",
    "\t\tword_model = Word2Vec.load(\"model_2\")\n",
    "\t\t#word_model.init_sims(replace=True)\n",
    "\treturn word_model\n",
    "\n",
    "getWord_model(2,200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine train data\n",
    "def combine(posfile, negfile, allfile):\n",
    "    f1 = open(posfile)\n",
    "    f2 = open(negfile)\n",
    "    g = open(allfile,'w')\n",
    "    g.write('lable\\tseq\\n')\n",
    "    for i in f1:\n",
    "        if '>'not in i:\n",
    "            g.write('1\\t'+i)\n",
    "    for i in f2:\n",
    "        if '>'not in i:\n",
    "            g.write('0\\t'+i)\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    g.close()\n",
    "\n",
    "combine('pos.fasta','neg.fasta','all.fasta')#'pos.fasta' contains positive samples with fasta format; 'neg.fasta' contains negative samples with fasta format; 'all.fasta' is a combination file of positive and negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA 0 of 13314\n",
      "DNA 1000 of 13314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\condaSetup\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA 2000 of 13314\n",
      "DNA 3000 of 13314\n",
      "DNA 4000 of 13314\n",
      "DNA 5000 of 13314\n",
      "DNA 6000 of 13314\n",
      "DNA 7000 of 13314\n",
      "DNA 8000 of 13314\n",
      "DNA 9000 of 13314\n",
      "DNA 10000 of 13314\n",
      "DNA 11000 of 13314\n",
      "DNA 12000 of 13314\n",
      "DNA 13000 of 13314\n",
      "\n",
      "(13314, 200)\n"
     ]
    }
   ],
   "source": [
    "#obtain feature file with .npy format\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\tDNAlist1 = []\n",
    "\t#DNAlist2 = []\n",
    "\tcounter = 0\n",
    "\tfor DNA in DNAdata[\"seq\"]:\n",
    "\t\t#if counter % 100 == 0:\n",
    "\t\t\t#print (\"DNA %d of %d\\r\" % (counter, 2*len(DNAdata)))\n",
    "\t\t\t#sys.stdout.flush()\n",
    "\n",
    "\t\tDNA = str(DNA).upper()\n",
    "\t\tDNAlist1.append(DNA2Sentence(DNA,word).split(\" \"))#[['ACG', 'CGT', 'GTC'],['ACG', 'CGT', 'GTC'],['ACG', 'CGT', 'GTC']]\n",
    "\n",
    "\t\tcounter += 1\n",
    "\treturn DNAlist1\n",
    "\n",
    "#\tprint()\n",
    "#\treturn DNAlist1,DNAlist2\n",
    "\n",
    "#def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "def getAvgFeatureVecs(DNAdata1,model,num_features):\n",
    "\tcounter = 0\n",
    "\tDNAFeatureVecs = np.zeros((len(DNAdata1),num_features), dtype=\"float32\")\n",
    "\tfor DNA in DNAdata1:\n",
    "\t\tif counter % 1000 == 0:\n",
    "\t\t\tprint (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "\t\t\tsys.stdout.flush()\n",
    "\n",
    "\t\tDNAFeatureVecs[counter][0:num_features] = np.mean(model[DNA],axis = 0)\n",
    "\t\tcounter += 1\n",
    "\tprint()\n",
    "\tcounter = 0\n",
    "\treturn DNAFeatureVecs\n",
    "\n",
    "def DNA2Sentence(dna, K):\n",
    "\tsentence = \"\"\n",
    "\tlength = len(dna)\n",
    "\n",
    "\tfor i in range(length - K + 1):\n",
    "\t\tsentence += dna[i: i + K] + \" \"\n",
    "\n",
    "\t#delete extra space\n",
    "\tsentence = sentence[0 : len(sentence) - 1]\n",
    "\treturn sentence\n",
    "\n",
    "data = pd.read_csv('all.fasta',sep = \"\\t\",error_bad_lines=False)\n",
    "#datawords1,datawords2 = getDNA_split(data,4)\n",
    "datawords1 = getDNA_split(data,2)#size of kmer\n",
    "#print(datawords1)\n",
    "\n",
    "word_model = Word2Vec.load(\"model_2\")#'model_2' is above generated in 'get model'\n",
    "#dataDataVecs = getAvgFeatureVecs(datawords1,datawords2,word_model,100)\n",
    "dataDataVecs = getAvgFeatureVecs(datawords1,word_model,200)\n",
    "print (dataDataVecs.shape)\n",
    "np.save(\"2_vecs.npy\",dataDataVecs)#outputFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13314\n"
     ]
    }
   ],
   "source": [
    "#convert file format (.npy to .txt/.csv)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "def npyToTXT(npyfile, svmfile, pos_num):\n",
    "    dataDataVecs = np.load(npyfile)\n",
    "    g = open(svmfile,'w')\n",
    "    print(len(dataDataVecs))\n",
    "    #print(dataDataVecs[0])\n",
    "\n",
    "    m = 0\n",
    "    for i in range(len(dataDataVecs)):\n",
    "        line = ''\n",
    "        for j in range(len(dataDataVecs[0])):\n",
    "            if j == len(dataDataVecs[0])-1:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "            else:\n",
    "                line += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "        m += 1\n",
    "        if m < (pos_num+1):\n",
    "            g.write('1\\t'+line)\n",
    "        else:\n",
    "            g.write('0\\t'+line)\n",
    "            \n",
    "def TXTtoCSV(svmfile, csvfile):\n",
    "\tf = open(svmfile,'r')\n",
    "\tg = open(csvfile,'w')\n",
    "\tlines = f.readlines()\n",
    "\tlegth = len(lines[0].split('\t'))-1\n",
    "\t#print(legth)\n",
    "\tclassline = 'class'\n",
    "\tfor i in range(legth):\n",
    "\t\tclassline += ',%d'%(i+1)\n",
    "\tg.write(classline+'\\n')\n",
    "\n",
    "\tfor line in lines:\n",
    "\t\tline = line.strip('\\n').split('\t')\n",
    "\t\tg.write(line[0]+',')\n",
    "\n",
    "\t\tlegth2 = len(line[1:])\n",
    "\t\tm = 0\n",
    "\t\tfor j in line[1:]:\n",
    "\t\t\tif m == legth2-1:\n",
    "\t\t\t\tj = j.split(':')[-1]\n",
    "\t\t\t\tg.write(j)\n",
    "\t\t\t\tm += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tj = j.split(':')[-1]\n",
    "\t\t\t\tg.write(j+',')\n",
    "\t\t\t\tm += 1\n",
    "\t\tg.write('\\n')\n",
    "\n",
    "\tf.close()\n",
    "\tg.close()\n",
    "    \n",
    "npyToTXT(\"2_vecs.npy\", '2_vecs.txt',6657)#positive number\n",
    "TXTtoCSV('2_vecs.txt', '2_vecs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
